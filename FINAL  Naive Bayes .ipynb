{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Loading the Pandas library and reading the dataset into a variable dfs, adding the column headers from a list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import pandas as pds\n",
    "dfs = pds.read_csv('C:\\\\Users\\\\Rahul Singh\\\\Downloads\\\\adult.data', header=None)\n",
    "head = [\"age\", \"workclass\",\"fnlwgt\",\"edu\",\"edu_num\",\"marital\",\"occupation\", \"relationship\",\"race\", \"sex\",\"capital_gain\",\"capital_loss\",\"hours per week\",\"nativecountry\",\"salary\"]\n",
    "dfs.columns = head"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Dropping the 19610th entry because of a singular attribute trait i.e. only one instance of Holland-Netherland in the entire dataset. The occurrence of a single instance in the  testing data means that this entry or value was not \"trained\", and hence wasn't included in the dictionary of probabilities, raising an error."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "dfs = dfs.drop(19609)\n",
    "dfs.index = range(dfs.shape[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Loading the required libraries like Gaussian Naive Bayes, NumPy, Statified KFold model from SciKitLearn, and creating an object of Gaussian NB and Stratified KFold"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn.naive_bayes import GaussianNB\n",
    "import numpy as np\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "skf = StratifiedKFold(n_splits=5)\n",
    "gnb = GaussianNB()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The folllowing function, \"cat_val\", accepts the training and testing data with categorical variables, calculates the predicted probabilities for each testing class, and returns the list of probabilities for each entity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def cat_val(x_train, y_train):\n",
    "    options = y_train.unique()  #Extracting Unique Test Classes\n",
    "    tr_size = x_train.shape[0]  #Total no. of occurrences\n",
    "    dfst = list(map(lambda x: (y_train==x).sum()/ tr_size, options))#Calculating probabilties of Each Test Class Occurrence\n",
    "    stolen_probs = pds.Series(dfst, index = options)              #Storing the result in a Series for further ease of reference\n",
    "    results_dicti = {}          #Initializing the Dictionary\n",
    "    for i in x_train:           #For each attribute in Train Data\n",
    "        sub_dicti = {}         \n",
    "        for j in x_train[i].unique():    #For Unique Values of Each Attribute \n",
    "            sub_dicti2 = {}\n",
    "            for k in options:            #For each Test Class\n",
    "                sub_dicti2[k] = x_train[(x_train[i]== j) & (y_train == k)].shape[0]/tr_size/stolen_probs[k]#Conditional Probability\n",
    "            sub_dicti[j] = sub_dicti2\n",
    "        results_dicti[i] = sub_dicti\n",
    "    return stolen_probs, results_dicti,options"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def predict_proba_cat (x_test, stolen_probs, results_dicti,options):\n",
    "    predict_list = np.empty((0,2))                             #create an empty array with 2 as the fixed no. of columns\n",
    "    for i in x_test.iterrows():                                # for all the entities in the test data\n",
    "        list1 = []                                             #(alternative)list1 = np.empty((1,0))\n",
    "        for k in options:                                      # For each Test Class\n",
    "            val = 1\n",
    "            for j in i[1].index:                               # For all the attributes of each entity\n",
    "                val = val * results_dicti[j][i[1][j]][k]       # Multiply the Conditional Probabilities of all the corresponding attribute values for each entity\n",
    "            list1.append(val*stolen_probs[k])                  #(alternative)append normally\n",
    "        finale = np.array([list1])                             #(alternative)remove this \n",
    "        predict_list = np.append(predict_list,finale,axis = 0) # store the corresponding probability for each test class of each entity\n",
    "    return predict_list"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The \"predi\" function is used for making predictions based upon the multiplied values and test classes given."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def predi (predictions,gnb):\n",
    "    list2 = []\n",
    "    for i in range(len(predictions)):  #traverse through the entire lst of predicted values\n",
    "        list2.append(gnb.classes_[np.where(predictions[i] == np.max(predictions[i]))[0]][0])  #find the max prob. of test class in each entity\n",
    "    return list2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The function \"accu\" calculates the accuracy of the predicted series"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def accu (pred,og):\n",
    "    return (pred == og).sum()/og.shape[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The function \"naive_baye\" accepts the loaded dataset and further calls the required functions used for calculating predictions, ultimately returning the final list of predictions "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def naive_baye (dfs):\n",
    "    x = dfs[dfs.columns[:-1]]        # Assume all the columns, except the last one, as attributes for Training Data\n",
    "    y = dfs[dfs.columns[-1]]         # Assume the last column as the Output(?) required\n",
    "    final_predictions_series = pds.Series(index = range(y.shape[0]) )\n",
    "    for train, test in skf.split(x,y):   # Use Stratified K fold to get Training and Testing Data\n",
    "        x_num_train = x[x.dtypes[x.dtypes==\"int64\"].index].iloc[train]  # Extract the Continuous Training Data\n",
    "        x_num_test = x[x.dtypes[x.dtypes==\"int64\"].index].iloc[test]    # Extract the Continuous Testing Data\n",
    "        y_train = y[train]\n",
    "        y_test = y[test]\n",
    "        gnb.fit(x_num_train, y_train)    # Fit the training Numerical data in the Gaussian  NB Object \n",
    "        num_pred_val = gnb.predict_proba(x_num_test)  # Store the Predicted Probabilities \n",
    "        x_cat_train = x[x.dtypes[x.dtypes==\"object\"].index].iloc[train] # Extract the Categorical Training Data\n",
    "        x_cat_test = x[x.dtypes[x.dtypes==\"object\"].index].iloc[test]   # Extract the Categorical Testing Data\n",
    "        stol,dictio,options = cat_val(x_cat_train, y_train)             # Fit the Training Data\n",
    "         cat_pred_val = predict_proba_cat(x_cat_test, stol, dictio,options)  #Store the Predicted Probabilites\n",
    "        predictions_values = np.multiply(num_pred_val,cat_pred_val)     #Multiply the values of Numerical and Categorical Probabilities\n",
    "        final_predictions = predi(predictions_values,gnb)               #Get the predictions\n",
    "        final_predictions_series.loc[test] = final_predictions          #Store these predictions in the form of a series with corresponding Test Index\n",
    "    naive_baye.accuracy = (final_predictions_series == y).sum()/y.shape[0]\n",
    "    return final_predictions_series "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "op = naive_baye(dfs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.75304054054054059"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "naive_baye.accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0          >50K\n",
       "1         <=50K\n",
       "2          >50K\n",
       "3         <=50K\n",
       "4         <=50K\n",
       "5         <=50K\n",
       "6          >50K\n",
       "7         <=50K\n",
       "8          >50K\n",
       "9          >50K\n",
       "10        <=50K\n",
       "11        <=50K\n",
       "12         >50K\n",
       "13         >50K\n",
       "14        <=50K\n",
       "15        <=50K\n",
       "16         >50K\n",
       "17         >50K\n",
       "18        <=50K\n",
       "19        <=50K\n",
       "20        <=50K\n",
       "21         >50K\n",
       "22        <=50K\n",
       "23         >50K\n",
       "24         >50K\n",
       "25        <=50K\n",
       "26         >50K\n",
       "27        <=50K\n",
       "28        <=50K\n",
       "29        <=50K\n",
       "          ...  \n",
       "32530     <=50K\n",
       "32531      >50K\n",
       "32532      >50K\n",
       "32533     <=50K\n",
       "32534     <=50K\n",
       "32535     <=50K\n",
       "32536     <=50K\n",
       "32537      >50K\n",
       "32538     <=50K\n",
       "32539     <=50K\n",
       "32540     <=50K\n",
       "32541     <=50K\n",
       "32542     <=50K\n",
       "32543     <=50K\n",
       "32544     <=50K\n",
       "32545     <=50K\n",
       "32546     <=50K\n",
       "32547     <=50K\n",
       "32548     <=50K\n",
       "32549     <=50K\n",
       "32550     <=50K\n",
       "32551     <=50K\n",
       "32552     <=50K\n",
       "32553     <=50K\n",
       "32554     <=50K\n",
       "32555     <=50K\n",
       "32556     <=50K\n",
       "32557     <=50K\n",
       "32558     <=50K\n",
       "32559      >50K\n",
       "Length: 32560, dtype: object"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "op"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
